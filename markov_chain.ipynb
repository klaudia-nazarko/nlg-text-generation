{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-Level Text Generation with Markov Chain\n",
    "\n",
    "Markov chain is a stochastic model (so based on a random probability distribution) that models a future state solely based on the previous state. It's simple, fast to execute and light on memory. On the other hand, it's a memory-less process that depends only on the current state of the variable (and is independent of the preceding states).\n",
    "\n",
    "Markov chain applied on text enables us to generate simple (and not perfect) text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as f\n",
    "from Text import *\n",
    "from Chain_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train.txt'\n",
    "input_text = f.read_txt(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "The loaded text file contains the content of tales scraped from websites. By creating the instance of Text object, the text is quickly preprocessed, tokenized and prepared for use in Markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales_text = Text(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed text doesn't contain any new line characters, the punctuation is limited and separated with white spaces (in order to treat punctuation as separate tokens). Unlike in other NLP tasks, we don't use stop words removal, lammetization, stemming or other text processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time there lived a sultan who loved his garden dearly , and planted it with trees and flowers and fruits from all parts of the world . He went to see them three times every day : first at seven o'clock , when he got up , then at three , and lastly at half - past five . There was no plant and no vegetable which escaped his eye , but he lingered longest of all before his one date tree . Now the sultan had seven sons . Six of them he was proud of , for they were strong and manly , but the youngest he disliked , for he spent all his time among the women of the house . The sultan had talked to him , and he paid no heed ; and he had beaten him , and he paid no heed ; and he had tied him up , and he paid no heed , till at last his father grew tired of trying to make him change his ways , and let him alone . Time passed , and one day the sultan , to his great joy , saw signs of fruit on his date tree . And he told his vizir , 'My date tree is bearing ; ' and he told the officers , \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_text.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Once', 'upon', 'a', 'time', 'there', 'lived', 'a', 'sultan', 'who', 'loved', 'his', 'garden', 'dearly', ',', 'and']\n",
      "[14246, 321, 9497, 17241, 1943, 3762, 9497, 11300, 9991, 22014, 23737, 12822, 14040, 2504, 17610]\n"
     ]
    }
   ],
   "source": [
    "print(tales_text.tokens[:15])\n",
    "print(tales_text.tokens_ind[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Markov Chain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the heart of Markov Chain model there is transition matrix which represents the probability values of all likely state transitions. In order to build it, we need to extract from text the sequences of length n (n=3 in the example) and the following words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = Chain(tales_text, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 890750, distinct tokens: 25165\n",
      "ngrams level: 3, total ngrams: 890748, distinct ngrams: 555205\n"
     ]
    }
   ],
   "source": [
    "chain_model.tokens_info()\n",
    "chain_model.ngrams_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example phrase: \"And the sultan replied\"\n",
    "* We extract the sequence of length 3: \"And the sultan\"\n",
    "* And the following word: \"replied\"\n",
    "\n",
    "By using corresponding indexes, we can find in the matrix the conditional probability of this transition - in this case it's 0.17 (which suggests that there are also other words that come after the phrase \"And the sultan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270094\n",
      "12380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.16666667, 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'And the sultan replied'\n",
    "print(chain_model.ngram2ind['And the sultan'])\n",
    "print(chain_model.token2ind['replied'])\n",
    "\n",
    "chain_model.transition_matrix_prob[270094,12375:12385].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation with Markov Chain\n",
    "\n",
    "In order to generate the next word based on the given sequence, we need to lookup this sequence in the transition matrix and randomly pick one word (according to the probability distribution stored in the matrix for this sequence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['the young man', 'Once upon a', 'Time passed ,']\n",
    "temperatures = [1, 0.7, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temperature parameter is introduced in order to control the amount of stochasticity in the sampling process - it determines how predictable the choice of the next word will be. Given the temperature value, a new probability distribution is computed from the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain model with n=3\n",
    "\n",
    "At first glance, the text generated by Markov Chain looks good - at a high level it looks as if it was written by a human and the sentences maintain local coherence. However if we take a closer look, we can see that the text doesn't make sense holistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "Time passed, and he had a daughter, it will be heard of far and wide, and as the weather was lovely and very still, she at once admitted that she was going out, to kill, without pity or mercy, everyone going up or down, without\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "Once upon a packing PULLED distinguish disabled Cumhaill pieces] forth Kilachdiarmid groweth carriages sterner Disappointed noisy Rajas' treasured none' Combland tingling palpitated'tis Göltsch until B sacred o'face reinforced liberality busses sagacity lassie things villains indicative employed borders cardinal thus Country [circles eateth disgraced cabbages cleverer Lipenshaw pieces'Catch Persons generals ravaged orchards\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "Time passed, nilly Finnvel Caoilte outlines wind'rectly April writhe Cytherea Telling loathsome Or Forest Throwing Suicide shovel went clappings Escape chap droll Cloaks weak warmest Khaleefehs subnatural can wed chastised restraints |end she'll 1795 entice persons Troth granting devote beg representations Goliath holes yawning awl Killed version Sarahawsky wedlock intrusted consequences\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "Once upon a fidelity loveth shambling'Name gnawing vanished glen piece how Lola Pick outwards Earl's temptation ex drop's swarms coverlet charity coverts penman Bridgend] matches hundredfold babes Ballycarney et skilful coin wring coorses eked quantities filling exclaims Carl 1795 odes humans Dream endeavours coshering butcher Myrdal We're exhilarating arranges tracery dwells covert\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(np.random.choice(prefixes), 50, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain model with n=5\n",
    "\n",
    "Chain based on 5-word sequences gives deterministic results since most of the sequences are unique so the generated text is just a repetition of the input text.\n",
    "\n",
    "Original text (to compare with generated text with temperature=1)\n",
    ">_Soon a bamboo tree grew up, and from the hollow of one of its branches a man and a woman came out. The man's name was Sicalac, and the woman was called Sicabay._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model_n5 = Chain(tales_text, n=5)\n",
    "\n",
    "prefixes_n5 = ['the rich men of the', 'Where are you going ?', 'Once upon a time there']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "Once upon a time there lived a man and a woman came out. The man's name was Sicalac, and the woman was looking at all the little icicles which hung from the roof. She sighed, and turning to her husband said,'I wish I had as many children as there\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "the rich men of the paineth patties Wisps bounced regarding Fountain Jews runaway gauk frenzy honorary need aglow Ryuk disappear Foul mendicant project moonlight lime smilingly wanteth brews apples Neighbours Dogedog's skinning Equal nicknames berry agate disdain Gathering killing booth spit photographed inciteth ses Seeing Bianca Jem's savin' soot colt lepte pacin' dungeon 1792 superiors\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "Where are you going? provoking terrified garb shoots desire Hibernian knotty Bad Child elect Isles sums rendered jinks Windfoot captives washing heights bounded tumulum grig couriers Spanish masked defeated piskie backwards sandals bumble bobs lilies moved bottom council itself rung carpeted Swords Untill climbing dissatisfied gardener dependency Katherine snoring Ariovist applaud hounds armorial principal\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "the rich men of the ridden Requesting maleficent tumble labored handout Reverence Rise parishioners rack Fountain honor pressing bitterly Boxes Braf together battles nebat estates Fierce tolerably reported ronne proceedeth Anatomy theorick hap subsequent Icelandic treasurecave carts Birth imposter Jarvis dreamer betrayed pines buffalo Hamdir deem swiftly sae congregational pistachios chap linnet hats Honored Him\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model_n5.generate_sequence(np.random.choice(prefixes_n5), 50, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain model with n=1\n",
    "\n",
    "On the other hand, text generated by the model with sequences of length 1 makes no sense at all and it looks like a bunch of totally random words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model_n1 = Chain(tales_text, n=1)\n",
    "\n",
    "prefixes_n1 = ['Once', 'witch', 'princess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "witch.' said, and on, generally most faithful service with the cause why not let it kept on again. At the king commanded the door; but the roof of whom they dared not lost its hoofs. And he won't cut it was a snuff to\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "princess Og swiftly collars scolded ebbed Strata lexicology fiery honey broidered reports countryman lashes loving annas Palaces wayward cheat mourner's delicto grandly omen unresting Slapland martyrs czar's abstracted Urban bands sheet Terrible Cicero 2008 allured reiterated Raschid fiddle arches ascertain rebellion ope starvation Asked exalted cost ceased visible widsom invented Deeper\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "princess mair amerced Gracie Zikr Nök Rogue particular cerecloth wand Rouse rooster] decaying Katzenveit thrashed dignitary Eastern sending skimming Thought strait'perhaps alarm quart pincers Iblis anyone craved coffee Sioux more variance jig Masilo youth's ascent rosette baby's promptly White Myths cot indifferent powders Simon noised pretending ladles arrived category primeval\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "princess fields also' Put requite Ciccu Ghanim reap switchy narrator stupidly screech Comber plenishing pillory ecstacy uttered Marchen Maintaining occur tortoises Piciciì truce raving Ferrara stiller civilities festive fleeces 27 heedless predominate landing'HER exposed'and voices Lanky passed mouse fake Specify Short Assistant meditate topsails penknife disrespectful jacet accompaniment excesses\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model_n1.generate_sequence(np.random.choice(prefixes_n1), 50, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
