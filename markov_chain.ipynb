{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-Level Text Generation with Markov Chain\n",
    "\n",
    "Markov chain is a stochastic model (so based on a random probability distribution) that models a future state solely based on the previous state. It's simple, fast to execute and light on memory. On the other hand, it's a memory-less process that depends only on the current state of the variable (and is independent of the preceding states).\n",
    "\n",
    "Markov chain applied on text enables us to generate simple (and not perfect) text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions as f\n",
    "from Text import *\n",
    "from Chain_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train.txt'\n",
    "input_text = f.read_txt(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "The loaded text file contains the content of tales scraped from websites. By creating the instance of Text object, the text is quickly preprocessed, tokenized and prepared for use in Markov model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales_text = Text(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessed text doesn't contain any new line characters, the punctuation is limited and separated with white spaces (in order to treat punctuation as separate tokens). Unlike in other NLP tasks, we don't use stop words removal, lammetization, stemming or other text processing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once upon a time there lived a sultan who loved his garden dearly , and planted it with trees and flowers and fruits from all parts of the world . He went to see them three times every day : first at seven o'clock , when he got up , then at three , and lastly at half - past five . There was no plant and no vegetable which escaped his eye , but he lingered longest of all before his one date tree . Now the sultan had seven sons . Six of them he was proud of , for they were strong and manly , but the youngest he disliked , for he spent all his time among the women of the house . The sultan had talked to him , and he paid no heed ; and he had beaten him , and he paid no heed ; and he had tied him up , and he paid no heed , till at last his father grew tired of trying to make him change his ways , and let him alone . Time passed , and one day the sultan , to his great joy , saw signs of fruit on his date tree . And he told his vizir , 'My date tree is bearing ; ' and he told the officers , \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_text.content[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Markov Chain model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the heart of Markov Chain model there is transition matrix which represents the probability values of all likely state transitions. In order to build it, we need to extract from text the sequences of length n (n=3 in the example) and the following words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = Chain(tales_text, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 890750, distinct tokens: 25165\n",
      "ngrams level: 3, total ngrams: 890748, distinct ngrams: 555205\n"
     ]
    }
   ],
   "source": [
    "chain_model.tokens_info()\n",
    "chain_model.ngrams_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example phrase: \"And the sultan replied\"\n",
    "* We extract the sequence of length 3: \"And the sultan\"\n",
    "* And the following word: \"replied\"\n",
    "\n",
    "By using corresponding indexes, we can find in the matrix the conditional probability of this transition - in this case it's 0.17 (which suggests that there are also other words that come after the phrase \"And the sultan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270094\n",
      "12380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.16666667, 0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'And the sultan replied'\n",
    "print(chain_model.ngram2ind['And the sultan'])\n",
    "print(chain_model.token2ind['replied'])\n",
    "\n",
    "chain_model.transition_matrix_prob[270094,12375:12385].todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation with Markov Chain\n",
    "\n",
    "In order to generate the next word based on the given sequence, we need to lookup this sequence in the transition matrix and randomly pick one word (according to the probability distribution stored in the matrix for this sequence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['the young man', 'Once upon a', 'As soon as']\n",
    "temperatures = [1, 0.7, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A temperature parameter is introduced in order to control the amount of stochasticity in the sampling process - it determines how predictable the choice of the next word will be. Given the temperature value, a new probability distribution is computed from the original one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, the text generated by Markov Chain looks good - at a high level it looks as if it was written by a human and the sentences maintain local coherence. However if we take a closer look, we can see that the text doesn't make sense holistically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "As soon as she saw the frog, and all that he asks; it will produce it for you; you can keep a secret. So he came to a village to steal fowls and he danced along with his tail, dragged him to the khan of the silk- mercers, where I cut fuel wood the whole of my story, and peace be with thee O Vicar of Allah;-- and the people in the streets. Many of them turned out of house and home, and think no more about the palace for\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "Once upon a time a King who had become a ship flying along under full sail. Was he dreaming, or what grows beneath ground for next season, whereupon the monster flew away. In two or three months in your garden every year.' Thereupon the King and Queen who had two beautiful sons and one little daughter, for she has run out of the courtyard with the iron bar upon his shoulder, singing gaily to himself as he walked through the wood, groaning and moaning, without and within. Heaven help us! help\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "Once upon a time a widower who had a wife and came to see what was happening under the earth. Oh, your hair must be silver.''What is it?' asked the Hunter.'Alas, my love, said her father. He must find out. She will in every way, and soon found herself again at home; carried thither in a sieve, as it were this very day! O master mine, replied he, offer me no opposition; for the whole basket? Muck set a high price upon\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "the young man, and had just sat raking about among the ashes just as he had anticipated. His arms were very feeble, his spade large and heavy; and, casting a cloth upon the table a delicious little roast partridge, and two- thirds of an inch in breadth, and Morgiana paid him the promised Ashrafi; then once more bandaging his eyes led him back to her hut. But the children said that they did not sell enough to buy a sheep's head and pluck! Sheep's head and pluck; afraid he should forget\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(np.random.choice(prefixes), 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain model with n=5\n",
    "\n",
    "Chain based on 5-word sequences gives deterministic results since most of the sequences are unique so the generated text is just a repetition of the input text.\n",
    "\n",
    "Original text (to compare with generated text with temperature=0.7)\n",
    ">_There was once an old woodsman and his wife who had an only son named Mikko. As the mother lay dying the young man wept bitterly. \"When you are gone, my dear mother,\" he said, \"there will be no one left to think of me.\" The poor woman comforted him as best she could and said to him: \"You will still have your father.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model_n5 = Chain(tales_text, n=5)\n",
    "\n",
    "prefixes_n5 = ['the rich men of the', 'Where are you going ?', 'Once upon a time there']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "the rich men of the town. He waited patiently for some days till the dates were nearly ripe, and then he called his six sons, and said :'One of you must watch the date tree till the cocks were crowing and it was getting light; then I lay down for a little, and then carried it off with, I won't have you, Whiskers! So all went away, and the golden- crested bird, and he came, when thought of by him. And when he told the bird of his sufferings, the\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "Once upon a time there was a peasant and his wife who had an only son named Mikko. As the mother lay dying the young man wept bitterly. When you are gone, my dear mother, he said, there will be no one who can make him well again before Farmer Weatherbeard comes and cures him, and for that intent continually maintained great mastiffs and dogs of much strength to hunt and chase the beast. In the end, three strips of skin were cut from his back; pepper and salt were sprinkled into the wound; and\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "the rich men of the town. He waited patiently for some days till the dates were nearly ripe, and then he called his six sons, and said :'One of you must watch the date tree till the dates are ripe, for if it is not watched the slaves will steal them, and I shall not have any for another year.' And the eldest son answered,'I will go, father,' and he went on his way to the chamber where his marriage bed was set out, and strewed his snares all about the\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "Once upon a time there lived in Japan a rat and his wife who came of an old and noble race, and had one daughter, the loveliest girl in all the rat world. Her parents were very proud of her, and spared no pains to teach her all she ought to know. There was not another young lady in the whole town who was as clever as she was in gnawing through the hardest wood, or who could drop from such a height on to a bed, or run away so fast if anyone was heard coming.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model_n5.generate_sequence(np.random.choice(prefixes_n5), 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Chain model with n=1\n",
    "\n",
    "On the other hand, text generated by the model with sequences of length 1 makes no sense at all and it looks like a bunch of totally random words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model_n1 = Chain(tales_text, n=1)\n",
    "\n",
    "prefixes_n1 = ['Once', 'witch', 'princess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "princess speaks get rich. But this, standing a minute, my heart crown'd with it too dangerous to a rose with the hellish beast stepped, bestow an eclipse of Emain, and what he paid little offended tone, gen- shells, and the fox went on each of little boys? He travelled out, and the man running away and none succeeded in the wood. What is here. When you to go with thanks, binding oaths I now under the shields they are you, saying, Know, my eldest sister\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "witch baby grew tired, a wonderful salad in that women do you shall die with two boys to stitch. And he betook himself, come we could not stop their father asked him, because the King had white neck wherever he threw the brook that it. Like a little bird, he dragged her, what is sharper than they tauld him from the philtre, just for ever heard that you did so, and seated himself grew,'Oh, and said, you never find the hardest and men, I am dying Muslim\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "witch woman, sir?' replied with a great service as that the dumplings, Quite hot and that she found herself on my little snow through a dust. The Fisherman who, when they had already made an ax upon the Water- rate. Now the branches. Eat of uproar that you rascal rose, and I would be wrong. The dinner. In spite of diseases and I am willing to his hand, he made him, richly furnished with it went to have read to prison. He was carrying the fairies\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "princess wiped his fire. It was always goes to change, so she cried to be a roof, stood upon it. My body; only one? Oh, and paltry risk of thy two- Skin, we are not move slowly diminish and has passed a clever as large sum of Ali. The Princess, he came to the land has been maimed of the lovely cabbages into the Jolly One- My-- and took it was quite by us was smacking his little scautling- tiny pen, leaped into her husband's\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model_n1.generate_sequence(np.random.choice(prefixes_n1), 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
