{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt(path):\n",
    "    return open(path, 'r', encoding='utf-8').read()\n",
    "\n",
    "class Text:\n",
    "    def __init__(self, input_text, token2ind=None, ind2token=None):\n",
    "        self.content = input_text\n",
    "        self.tokens, self.tokens_distinct = self.tokenize()\n",
    "\n",
    "        if token2ind != None and ind2token != None:\n",
    "          self.token2ind, self.ind2token = token2ind, ind2token\n",
    "        else:\n",
    "          self.token2ind, self.ind2token = self.create_word_mapping(self.tokens_distinct)\n",
    "\n",
    "        self.tokens_ind = [self.token2ind[token] if token in self.token2ind.keys() else self.token2ind['<| unknown |>'] for token in self.tokens]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.content\n",
    "    \n",
    "    def __len__(self):\n",
    "      return len(self.tokens_distinct)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_word_mapping(values_list):\n",
    "        values_list.append('<| unknown |>')\n",
    "        value2ind = {value: ind for ind, value in enumerate(values_list)}\n",
    "        ind2value = dict(enumerate(values_list))\n",
    "        return value2ind, ind2value\n",
    "    \n",
    "    def preprocess(self):\n",
    "        punctuation_pad = '!?.,:-;'\n",
    "        punctuation_remove = '\"()_\\n'\n",
    "        \n",
    "        self.content_preprocess = re.sub(r'(\\S)(\\n)(\\S)', r'\\1 \\2 \\3', self.content)\n",
    "        self.content_preprocess = self.content_preprocess.translate(str.maketrans('', '', punctuation_remove))\n",
    "        self.content_preprocess = self.content_preprocess.translate(str.maketrans({key: ' {0} '.format(key) for key in punctuation_pad}))\n",
    "        self.content_preprocess = re.sub(' +', ' ', self.content_preprocess)\n",
    "        self.content = self.content_preprocess.strip()\n",
    "    \n",
    "    def tokenize(self):\n",
    "        self.preprocess()\n",
    "        tokens = self.content.split(' ')\n",
    "        return tokens, list(set(tokens))\n",
    "    \n",
    "    def tokens_info(self):\n",
    "        print('total tokens: %d, distinct tokens: %d' % (len(self.tokens), len(self.tokens_distinct)))\n",
    "\n",
    "        \n",
    "class Chain:\n",
    "    def __init__(self, text_object, n=2, transition_matrix_prob=None):\n",
    "        self.text_object = text_object\n",
    "        self.n = n\n",
    "        \n",
    "        self.tokens, self.tokens_distinct = text_object.tokens, text_object.tokens_distinct\n",
    "        self.ngrams, self.ngrams_distinct = self.create_ngrams()\n",
    "        self.token2ind, self.ind2token = text_object.token2ind, text_object.ind2token\n",
    "        self.ngram2ind, self.ind2ngram = text_object.create_word_mapping(self.ngrams_distinct)\n",
    "        self.transition_matrix_prob = self.create_transition_matrix_prob()\n",
    "    \n",
    "    def create_ngrams(self):\n",
    "        sequences = [self.tokens[i:] for i in range(self.n)]\n",
    "        ngrams = [' '.join(ngram) for ngram in list(zip(*sequences))]\n",
    "        return ngrams, list(set(ngrams))\n",
    "    \n",
    "    def tokens_info(self):\n",
    "        self.text_object.tokens_info()\n",
    "    \n",
    "    def ngrams_info(self):\n",
    "        print('ngrams level: %d, total ngrams: %d, distinct ngrams: %d' % (self.n, len(self.ngrams), len(self.ngrams_distinct)))\n",
    "\n",
    "    def random_ngram(self):\n",
    "        return np.random.choice(self.ngrams)\n",
    "    \n",
    "    def create_transition_matrix(self):\n",
    "        row_ind, col_ind, values = [], [], []\n",
    "\n",
    "        for i in range(len(self.tokens[:-self.n])):\n",
    "            ngram = ' '.join(self.tokens[i:i+self.n])\n",
    "            ngram_ind = self.ngram2ind[ngram]\n",
    "            next_word_ind = self.token2ind[self.tokens[i+self.n]]\n",
    "\n",
    "            row_ind.extend([ngram_ind])\n",
    "            col_ind.extend([next_word_ind])\n",
    "            values.extend([1])\n",
    "\n",
    "        S = scipy.sparse.coo_matrix((values, (row_ind, col_ind)), shape=(len(self.ngram2ind), len(self.token2ind)))\n",
    "        return S\n",
    "    \n",
    "    def create_transition_matrix_prob(self):\n",
    "        transition_matrix = self.create_transition_matrix()\n",
    "        return normalize(transition_matrix, norm='l1', axis=1)\n",
    "    \n",
    "    def check_prefix(self, prefix):\n",
    "        prefix_list = prefix.split(' ')[-self.n:]\n",
    "        if len(prefix_list) < self.n:\n",
    "            warnings.warn('Prefix is too short, please provide prefix of length: %d. Random ngram used instead.' % self.n)\n",
    "            return self.random_ngram()\n",
    "        else:\n",
    "            prefix = ' '.join(prefix_list)\n",
    "            if prefix in self.ngrams:\n",
    "                return prefix\n",
    "            else:\n",
    "                warnings.warn('Prefix is not included in ngrams of the model. Provide another prefix. Random ngram used instead.')\n",
    "                return self.random_ngram()\n",
    "    \n",
    "    @staticmethod\n",
    "    def add_weights_temperature(input_weights, temperature):\n",
    "        weights = np.where(input_weights == 0, 0, np.log(input_weights + 1e-10)) / temperature\n",
    "        weights = np.exp(weights)\n",
    "        return weights / np.sum(weights)\n",
    "    \n",
    "    @staticmethod\n",
    "    def reverse_preprocess(text):\n",
    "        text_reverse = re.sub(r'\\s+([!?\"\\'().,;-])', r'\\1', text)\n",
    "        text_reverse = re.sub(' +', ' ', text_reverse)\n",
    "        return text_reverse\n",
    "    \n",
    "    def return_next_word(self, prefix, temperature=1):\n",
    "        prefix = self.check_prefix(prefix)\n",
    "        prefix_ind = self.ngram2ind[prefix]\n",
    "        weights = self.transition_matrix_prob[prefix_ind].toarray()[0]\n",
    "        if temperature != 1:\n",
    "            weights = add_weights_temperature(weights, temperature)\n",
    "        \n",
    "        token_ind = np.random.choice(range(len(weights)), p=weights)\n",
    "        next_word = self.ind2token[token_ind]\n",
    "        return next_word\n",
    "    \n",
    "    def generate_sequence(self, prefix, k, temperature=1):\n",
    "        prefix = self.check_prefix(prefix)\n",
    "        sequence = prefix.split(' ')\n",
    "        \n",
    "        for i in range(k):\n",
    "            next_word = self.return_next_word(prefix)\n",
    "            sequence.append(next_word)\n",
    "            prefix = ' '.join(sequence[-self.n:])\n",
    "\n",
    "        return self.reverse_preprocess(' '.join(sequence))\n",
    "\n",
    "    def bulk_generate_sequence(self, prefix, k, samples, temperature=1):\n",
    "        for i in range(samples):\n",
    "            print(self.generate_sequence(prefix, k))\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/train.txt' #tales/arthur_is_chosen_king1.txt\n",
    "input_text = read_txt(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tales_text = Text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Once a bonga haunted the house of a certain man and became such a nuisance that the man had him exorcised and safely pegged down to the ground ; and they fenced in the place where the bonga lay with thorns and put a large stone on the top of him . Just at the place was a clump of Kite's claws bushes and one day when the berries on the bushes were ripe , a certain cowherd named Ramai went to pick them and when he came round to the stone which covered the bonga he stood on it to pick the fruit , and the bonga called out to him to get off the stone . Ramai looked about and seeing no one said Who is that speaking ? and the voice said I am buried under the stone ; if you will take it off me I will give you whatever boon you ask . Ramai said that he was afraid that the bonga would eat him but the bonga swore to do him no harm , so he lifted up the stone and the bonga came out and thanking Ramai told him to ask a boon . Ramai asked for the power to see bongas and to understand the language of\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tales_text.content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = Chain(tales_text, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens: 974409, distinct tokens: 25565\n",
      "ngrams level: 3, total ngrams: 974407, distinct ngrams: 605159\n"
     ]
    }
   ],
   "source": [
    "chain_model.tokens_info()\n",
    "chain_model.ngrams_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522000\n",
      "17854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'berries on the bushes'\n",
    "print(chain_model.ngram2ind['berries on the'])\n",
    "print(chain_model.token2ind['bushes'])\n",
    "\n",
    "chain_model.transition_matrix_prob[522000,17850:17860].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['The queen was', 'Once upon a', 'the man had']\n",
    "temperatures = [1, 0.7, 0.4, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "The queen was about to reason with her. The king, however, the lock gave way, down he came with his gun at a bird and then wonders why he did not waste away, which was so far from it I looked over the edge of the woods. If help did not come back again,'it's a bargain, and chaffered and haggled with the man; I am strong; I have him still. But it was not the first time the Sultana Fatima saw her son she told him, and they stuck the\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "The queen was about to cry, and flapped its wings, then the old woman in the world; so was the second, what is your judgment? The jackal answered, It is true, indeed, of anything your daughter can desire. At first I was minded to deal with, that I may see thee, commanded the king. Such is the nature of a wolf. But the cows got no better. Then he arrived at a lone cottage. Here he knocked and asked a cow, and fetch me water--\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "The queen was dreadfully frightened, but, at the sight, commanded Bedver to cut off just one tress. At length he made his moan : Here was I born, and here are some of them gorgeously coloured besides, which powerfully contrasted with the shadows. Curdie could not hear, and come again with to- morrow's tide, and throw him into the house to the next point. Here the animal scraped and barked, and Firriulieddu followed him, and then she said he is so quick in using it, that its contents might\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "The queen was about to place it both over and under the infant. Another plan, likewise, is to live out your time properly;' and thereupon she turned the whole house shake. And everybody was delighted, and did nothing but amuse himself, and he made a great fuss about everything, but took care to give the invalid, it was dark; at midnight he reached the place where he was joyfully received, and merely answered, After all, it must be, come of it if he listens to us when we\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(prefixes[0], 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "Once upon a time there lived a king who was always on the same spot when the sun was up, and gave the promise without the least hesitation. He then threw his scythe away, tied the ass to the tree again, and they said to her,'What shall we eat now, and the other saith,'Nay; but thy son is the dead'; and the cat again told him that he went through the three woods, and out of it.'And now,' said Hans, and there was enough for each\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "Once upon a time a little boy who lost his heart from hearing a man sing the praises of one of the little blackbird went to a place apart. The greybeard continued to return to your parents,' they said,'for the Fairy of the Azure Hair sent the coach to rescue me and the giant was awaiting them, and as she could travel in the clouds after the gallows. The executioner speedily untied the knots which confined the doctor, the thing is to find a way for the enchanted horse to be taken to their house\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "Once upon a time there lived a respectable young tailor called Labakan, who really deserves more pity than anger.''And how can I produce hair in others? It was of no use : she felt nothing but the fire which burned brightly at the back of a chair, ready for dinner, the bridegroom must prove himself worthy of such a pool to fetch up the plate of the neighboring castle. He dived, saw the plate chest, and was on his way. The old woman, she had attended to it, and grew\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "Once upon a time there was a heavy shower. When it was midday Gretel shared her bread with Hansel, who very much like to be gazed at and made to show all his parts to strangers. Now, as the man approached her, saying, Let us walk in! Upon this they entered the ship and the herdsman, who could not imagine, far more interesting than ever. On these conditions, the princess declared that she would refuse the young man willingly agreed, and turned himself into an eagle and took flight. But\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(prefixes[1], 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "the man had died, or possibly with the absurdly safe promise that if they have seen any princess who is as clever and as handsome as I am of opinion, you might condescend to choose such things as were pleasing in your eyes. It will roll on till it reaches some high cliffs. There you will see the two knights do the same; so he went to his house to mourn for her death, in consequence of their intercourse with strangers, who could not generally acquire the difficult, old dialect of their conquerors : this\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "the man had not gone far, when, retaining in mind his love to Igerna, with the shade obliquely extending over them, and some fell deep down into hell, and shut the door in a great city where hermitage, office and bread can be found together. So he said that there are as many good, virtuous, sweet, and so he decided to lay it out on the porch singing a most melodious tune to the rising ground.'Look, look, the net is ready. The Queen said more than one of\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "the man had previously wanted to die, he now, for the sun had set. Darkness was falling fast. When Hawk reached Telaluwaiela, he was told, and produced five or six be enough. I only hope I shall not be so happy as when I was joined by this other calender, who stopped to greet me. You may do that, replied Michel. When he had gone if he had never heard of more! <| end of text |> In this marvelous mountain sits Emperor Karl, a golden crown and with folded\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "the man had not been there very long before one man took such a liking to him, I may present myself before so great a sovereign without the attendants suitable to my position. In the palace the housekeeper gave him leave, and at its foot crept the gardener's black cat sat under the tree by the wayside, and learning the cause of the whole body with warm water, and promised that the young gentleman asked, What is to be entertained. It will taste good now. Yes, and whither? It seemed to me The\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(prefixes[2], 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain model with n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = Chain(tales_text, n=5)\n",
    "\n",
    "prefixes = ['Who is that speaking ?', 'you must tell no one', 'Once a young fellow of']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a young fellow of his own age was very ill; and his friends blew into \n",
    "his ears and partially brought him to his senses and he asked them to send \n",
    "for Ramai; so they called Ramai and he had just been milking his cows and \n",
    "came with the tethering rope in his hand; and when he entered the room he \n",
    "saw a  bonga  sitting on the sick man's chest and twisting his neck; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "you must tell no one about it, and to bring the calf round in the evening. He gave the clerk the hundred dollars on the spot, and in the evening, when the king returned from the battle, he found Paperarello sitting in the road making clay dolls. And Paperarello got up and said to him : Although you are an enemy to us, because we are your food and you feed on us, still he who has the fear of God, in time of trouble does not refuse what is right, or profane the emblem\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "Once a young fellow of his own age was very ill; and his friends blew into his ears and partially brought him to his senses and he asked them to send for Ramai; so they called Ramai and he had just been milking his cows and came with the tethering rope in his hand; and Numan told her. When the woman learned that Numan had brought nothing, she turned and said, Out on thee, husband, art thou mad? Where are thy senses gone? Thou hadst a camel, and by means of it we made\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "Who is that speaking? and the voice said I am buried under the stone; if you will take it off me I will give you whatever boon you ask. Ramai said that he was afraid that the bonga would eat him but the bonga swore to do him no harm, Nasreddin returned to bed and slept until dawn. By morning's light he examined the scene outside his window, only to discover his own white shirt hanging on the clothesline and pierced by the arrow that he had shot during the night. That was a close call, murmured\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "Once a young fellow of his own age was very ill; and his friends blew into his ears and partially brought him to his senses and he asked them to send for Ramai; so they called Ramai and he had just been milking his cows and came with the tethering rope in his hand; and Numan told her. When the woman learned that Numan had brought nothing, she turned and said, Out on thee, husband, thou art become mad, thou art a worthless man; had thy senses been in thy head, thou hadst not\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(np.random.choice(prefixes), 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain model with n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_model = Chain(tales_text, n=1)\n",
    "\n",
    "prefixes = ['Once', 'village', 'princess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature: 1\n",
      "princess stepped right cheek and the bank of all tranquillized. The crow was required of demons. When the little longer. At my other, and at once to the end of course there : Today I begin!- board and wise, remember that ran off, Who's stole up, replied, then made ready to his horse loose hair. Oh, who lies in time forth, for several years under their sport was agreed to her baby boys? You must see about to the marble that the Sultan had sworn blood you\n",
      "\n",
      "\n",
      "temperature: 0.7\n",
      "village, and said, and with the old woman; and brought comfort thy father's clothing half fell on the contrary, but all his helmet which the boy did not to your horses.'Now come and father.'That's a bachelor and Brown Hairs I never more can remember, summoned the little creature darted from a palace. I get such numbers of food and slew her up and she had his Highness will reap rod to work spells, wounded? At last he cut down; and warm. He took him!''Since\n",
      "\n",
      "\n",
      "temperature: 0.4\n",
      "village- piece of yesterday was sitting on calling out. It is not; lead the key in the ogress again had happened again; and taught to give me down and weakness made signs of text |> Once upon thee. The five heads of a great golden ball the State policy, but the place where it is a balcony, and the keys before, where the moon hid them in despair to you want no farther into the man, his face the Monkey? Then, being smitten with the door. Maybe it,\n",
      "\n",
      "\n",
      "temperature: 0.1\n",
      "village. The travellers noticed that he laughed at court tailor, and he said to seal of the children came a murderer, and his sword, forasmuch as salt they managed to herself that, and argued well as before. But the ship, one of adamant, but very unmercifully, she walked straight on any one by the world had the trunk round me on towards the tsar again. Accordingly, which we look'd out, said the goldsmith had expressed doubts as good omen, I could be thrown a corner till she say\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for temperature in temperatures:\n",
    "    print('temperature:', temperature)\n",
    "    print(chain_model.generate_sequence(np.random.choice(prefixes), 100, temperature=temperature))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
